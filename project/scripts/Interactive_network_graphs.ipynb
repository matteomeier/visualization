{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine, EdgesAndLinkedNodes, NodesAndLinkedEdges, Label\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.palettes import viridis\n",
    "from bokeh.transform import linear_cmap\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1970c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50808abb",
   "metadata": {},
   "source": [
    "# Interactive Network Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7d263b",
   "metadata": {},
   "source": [
    "#### Why a network graph?\n",
    "A network graph makes the information which is contained in over one million tweets easily graspable for the viewer. The size of nodes and edges as well as the color give us additional tools to make the visualization more intuitive like the bigger the size of a node the more important it is. This type of graph also makes it easy to verify certain assumptions, for example one could assume that politicians and their party are often mentioned together in a tweet. As the visualization of the mention network will show this assumption can be proven to be right. Another advantage of this network implementation is it´s interactivity. Problems of static network graphs like overlaying labels can be easily overcome by zooming into the network. Moreover, hovering and selecting functions enable the viewers to explore the data themselves. Especially after giving a more straightforward analysis of the data in the previous parts of our report, this last chapter is intended to give the viewers the possibility to interact with the data in a less prescribed way.\n",
    "\n",
    "The following code is based on the implementation of an interactive network graph from the book 'Introduction to Cultural Analytics & Python' written by Melanie Walsh {cite}`Walsh.2021`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "\n",
    "# Hashtag network\n",
    "path = r'../data/hashtags_weighted_edges.json'\n",
    "title_subject = 'Hashtag'\n",
    "min_weight = 325 # for pre-filtering of data\n",
    "network_layout = networkx.kamada_kawai_layout\n",
    "layout_args = {'scale':10, 'weight': 'weight'}\n",
    "hashtag_config = {'path':path, 'title_subject': title_subject, 'min_weight': min_weight, 'network_layout': network_layout, 'layout_args': layout_args}    \n",
    "\n",
    "# Mention network\n",
    "path = r'../data/mentions_weighted_edges.json'\n",
    "title_subject = 'Mention'\n",
    "min_weight = 400 # for pre-filtering of data\n",
    "network_layout = networkx.spring_layout\n",
    "layout_args = {'scale':10, 'k': 2, 'iterations': 50, 'seed': 2, 'weight': 'weight'}\n",
    "mention_config = {'path':path, 'title_subject': title_subject, 'min_weight': min_weight, 'network_layout': network_layout, 'layout_args': layout_args}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Network Visualization with Bokeh\n",
    "def plot_network(path, title_subject, min_weight, network_layout, layout_args):\n",
    "    # load preprocessed file\n",
    "    df = pd.read_json(path)\n",
    "\n",
    "    # Filter data (drop edges with a weight less than min_weight)\n",
    "    df_filtered = df.drop(df[df.weight < min_weight].index)\n",
    "\n",
    "    # Create network graph\n",
    "    G = networkx.from_pandas_edgelist(df_filtered, 'source', 'target', 'weight')\n",
    "\n",
    "    # Remove components with less than n connections \n",
    "    # (so that there will be no free floating mini-graphs disconnected from the network)\n",
    "    n_connections = 4\n",
    "    for component in list(networkx.connected_components(G)):\n",
    "        if len(component)<n_connections:\n",
    "            for node in component:\n",
    "                G.remove_node(node)\n",
    "                \n",
    "    # Print basic network data\n",
    "    print('Number of Nodes:', G.number_of_nodes())\n",
    "    print('Number of Edges:', G.number_of_edges())\n",
    "\n",
    "    # Calculate degree for each node and add as node attribute\n",
    "    degrees = dict(networkx.degree(G))\n",
    "    networkx.set_node_attributes(G, name='degree', values=degrees)\n",
    "\n",
    "    # Adjust degree so that the nodes with very small degrees are still visible\n",
    "    number_to_adjust_by = 5\n",
    "    adjusted_node_size = dict([(node, degree+number_to_adjust_by) for node, degree in networkx.degree(G)])\n",
    "    networkx.set_node_attributes(G, name='adjusted_node_size', values=adjusted_node_size)\n",
    "\n",
    "    # Adjust weight so that the width of the edges does not exceed the smaller node size\n",
    "    weight_list = [attr['weight'] for _, _, attr in G.edges(data=True)]\n",
    "    weight_min = 1\n",
    "    weight_max = 10\n",
    "    weight_scaler = preprocessing.MinMaxScaler(feature_range=(weight_min, weight_max))\n",
    "    weight_normalized = weight_scaler.fit_transform(np.asarray(weight_list).reshape(-1, 1))\n",
    "\n",
    "    # Add normalized edge weight\n",
    "    edge_attrs = {}\n",
    "    for edge, weight_norm in zip(G.edges(data=True), weight_normalized):\n",
    "        edge_attrs[(edge[0], edge[1])] = weight_norm[0]\n",
    "    networkx.set_edge_attributes(G, edge_attrs, 'normalized_weight')\n",
    "\n",
    "    # Calcualte communities\n",
    "    communities = networkx.algorithms.community.greedy_modularity_communities(G)\n",
    "    print(\"Number of communities:\", len(communities))\n",
    "\n",
    "    # The biggest n communities should be distinguishable by color\n",
    "    n_biggest_communities = 8\n",
    "    if len(communities) < n_biggest_communities:\n",
    "        color_palette = list(viridis(len(communities)))\n",
    "        color_palette.reverse()\n",
    "    else:    \n",
    "        color_palette = list(viridis(n_biggest_communities))\n",
    "        color_palette.reverse()\n",
    "        color_palette.extend(['black'] * (len(communities)-8))\n",
    "\n",
    "    # Create empty dictionaries\n",
    "    modularity_class = {}\n",
    "    modularity_color = {}\n",
    "    #Loop through each community in the network\n",
    "    for community_number, community in enumerate(communities):\n",
    "        #For each member of the community, add their community number and a distinct color\n",
    "        for name in community: \n",
    "            modularity_class[name] = community_number        \n",
    "            modularity_color[name] = color_palette[community_number]\n",
    "\n",
    "    # Add modularity class and color as attributes to network graph\n",
    "    networkx.set_node_attributes(G, modularity_class, 'modularity_class')\n",
    "    networkx.set_node_attributes(G, modularity_color, 'modularity_color')\n",
    "\n",
    "    def get_halfway_color(c1, c2):\n",
    "        r1, g1, b1 = [int(c1[p:p+2], 16) for p in range(1,6,2)]\n",
    "        r2, g2, b2 = [int(c2[p:p+2], 16) for p in range(1,6,2)]\n",
    "        c = '#{:02x}{:02x}{:02x}'.format((r1+r2) // 2, (g1+g2) //2, (b1+b2)// 2)\n",
    "        return c\n",
    "\n",
    "    # Add edge color\n",
    "    edge_attrs = {}\n",
    "    for start_node, end_node, _ in G.edges(data=True):\n",
    "        edge_color = G.nodes[start_node]['modularity_color'] if G.nodes[start_node]['modularity_color'] == G.nodes[end_node]['modularity_color'] else get_halfway_color(G.nodes[start_node]['modularity_color'], G.nodes[end_node]['modularity_color'])\n",
    "        edge_attrs[(start_node, end_node)] = edge_color\n",
    "    networkx.set_edge_attributes(G, edge_attrs, \"edge_color\")\n",
    "\n",
    "    # Choose colors for node and edge highlighting\n",
    "    node_highlight_color = 'white'\n",
    "    selection_color = 'skyblue'\n",
    "    hover_color = 'red'\n",
    "\n",
    "    # Choose attributes from G network to size and color by — setting manual size (e.g. 10) or color (e.g. 'skyblue') also allowed\n",
    "    size_by_this_attribute = 'adjusted_node_size'\n",
    "    color_by_this_attribute = 'modularity_color'\n",
    "\n",
    "    # Choose a title\n",
    "    title = f'{title_subject} Network'\n",
    "\n",
    "    # Establish which categories will appear when hovering over each node\n",
    "    HOVER_TOOLTIPS = [\n",
    "            (f\"{title_subject}\", \"@index\"),\n",
    "            (\"Degree\", \"@degree\"),\n",
    "            (\"Modularity Class\", \"@modularity_class\"),\n",
    "            (\"Modularity Color\", \"$color[swatch]:modularity_color\"),\n",
    "    ]\n",
    "\n",
    "    # Create a plot — set dimensions, toolbar, and title\n",
    "    plot = figure(tooltips = HOVER_TOOLTIPS,\n",
    "                  tools=\"tap,pan,wheel_zoom,save,reset\", active_scroll='wheel_zoom',\n",
    "                  x_range=Range1d(-10.1, 10.1), y_range=Range1d(-10.1, 10.1), title=title, width=1000, height=1000)\n",
    "\n",
    "    # Create a network graph object\n",
    "    network_graph = from_networkx(G, network_layout, **layout_args, center=(0, 0))\n",
    "\n",
    "    # Set node sizes and colors according to node degree (color as category from attribute)\n",
    "    network_graph.node_renderer.glyph = Circle(size=size_by_this_attribute, fill_color=color_by_this_attribute, fill_alpha = 1)\n",
    "    # Set node highlight colors\n",
    "    network_graph.node_renderer.selection_glyph = Circle(size=size_by_this_attribute, fill_color=node_highlight_color, line_color=selection_color, line_width=2)\n",
    "    network_graph.node_renderer.hover_glyph = Circle(size=size_by_this_attribute, fill_color=node_highlight_color, line_color=hover_color, line_width=2)\n",
    "\n",
    "    # Set edge opacity and width\n",
    "    network_graph.edge_renderer.glyph = MultiLine(line_color='edge_color', line_width='normalized_weight', line_alpha=0.3)\n",
    "    # Set edge highlight colors\n",
    "    network_graph.edge_renderer.selection_glyph = MultiLine(line_color=selection_color, line_width='normalized_weight')\n",
    "    network_graph.edge_renderer.hover_glyph = MultiLine(line_color=hover_color, line_width='normalized_weight')\n",
    "\n",
    "    # Highlight nodes and edges\n",
    "    network_graph.selection_policy = NodesAndLinkedEdges()\n",
    "    network_graph.inspection_policy = NodesAndLinkedEdges()\n",
    "    plot.renderers.append(network_graph)\n",
    "\n",
    "    # Add Labels (with normalized font size)\n",
    "    x, y = zip(*network_graph.layout_provider.graph_layout.values())\n",
    "    node_labels = list(G.nodes())\n",
    "    font_size_min = 8\n",
    "    font_size_max = 25\n",
    "    font_size_raw = [G.degree(node_labels[i]) for i in range(len(x))]\n",
    "    font_size_scaler = preprocessing.MinMaxScaler(feature_range=(font_size_min, font_size_max))\n",
    "    font_size_normalized = font_size_scaler.fit_transform(np.asarray(font_size_raw).reshape(-1, 1))\n",
    "    font_size_normalized = [str(label_font_size[0]) + 'px' for label_font_size in font_size_normalized]\n",
    "    source = ColumnDataSource({'x': x, 'y': y, 'name': [node_labels[i] for i in range(len(x))], 'font_size_normalized': font_size_normalized})\n",
    "    labels = []\n",
    "    for x, y, label, fontsize in zip(source.data['x'], source.data['y'], source.data['name'], source.data['font_size_normalized']):\n",
    "        labels.append(Label(x=x, y=y, text=label, level='glyph', text_font_style='bold', background_fill_color='white', background_fill_alpha=.6, text_align ='center', text_baseline = 'bottom', text_font_size=fontsize))\n",
    "        plot.add_layout(labels[-1])\n",
    "\n",
    "    show(plot)\n",
    "    return plot, G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b76591",
   "metadata": {},
   "source": [
    "#### General description of the network graphs\n",
    "The size of the node represents the number of different edges the respective node has, i.e. the number of different accounts it was mentioned with. Each node has a label, the size of the label is scaled according to the node size. The depicted data was pre-filtered by the weight of the edges, which is defined as the number of times two hashtags were used in the same tweet. We enforced a minimum weight to ensure that the network does no get to big, thus, focusing on the most important relations (edges with highest weights). The color of the nodes represents different communities within the network which were detected by using Clauset-Newman-Moore greedy modularity maximization. The color of the edges also represent the communities of the nodes they connect, if the communities of the connected nodes differ the edge was given a color between those two community colors. The width of the edges is given by the weight, i.e. how often the two connected hashtags were used together. The plot contains some interactive elements. It is possible to zoom in and out, to hover over nodes and to select a node. Hovering and selecting leads to a highlighting of all neighboring nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8095d71",
   "metadata": {},
   "source": [
    "## The hashtag network \n",
    "\n",
    "The nodes of the hashtag network comprise the hashtags that were ever used in tweets during the election period. The edges are defined as the use of two hashtags in the same tweet. For example, if the hashtags #btw17 and #spd were both used in the same tweet it was counted as an edge between those nodes.\n",
    "\n",
    "We decided to create a network based on hashtags because, as mentioned above, it allows the viewer to verify certain assumptions. While showing data that was already used in our previous analyses (statistics of the most used hashtags) the hashtag network presents the user additional information in the form of the hashtags with which the most widespread hashtags were used together (and which are themselves to small to appear in the top ten most used hashtags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot, G = plot_network(**hashtag_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e370fe",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "The detected clusters (communities) give us a chance to identify topics which were important during the election period. We discovered clusters, which represent topics like 'G20' (g20 summit), 'Dieselgate' (Diesel emissions scandal), 'Erdogan' and 'Ehe für alle' (same-sex marriage). Interestingly some of theese topics where already identified as possible topics during our introduction of the dataset and can be confirmed using this graph network.\n",
    "Besides topics, we can also identify clusters which are dominated by one political party like the <i>AfD</i> cluster (yellow). As we have already seen through the previous analyses the <i>AfD</i> related hashtags #afd and #traudichdeutschland are next to #btw17 the most connected hashtags in this network. Moreover, we can observe that the parties <i>SPD</i>, <i>Die Grünen</i>, <i>Die Linke</i>, <i>FDP</i>, <i>CDU</i> and <i>CSU</i> are considered to be in one cluster while the <i>AfD</i> is represented by two clusters (one surrounding #afd and the other one surrounding the slogan of the <i>AfD</i> #traudichdeutschland). This shows how dominating the <i>AfD</i> related tweets are in our dataset, and thus in the election period overall, compared to the one relating to other political parties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e8fb5",
   "metadata": {},
   "source": [
    "## The mention network \n",
    "\n",
    "The nodes of the mention network are the mentions in form of their screen name (i.e. @screen_name). The edges are defined as mentions of two accounts in the same tweet, e.g. if the accounts @dielinke and @die_gruenen were both mentioned in one tweet it was counted as an edge between those nodes. The data does not account for the relationship between the account who created or retweeted the given tweet and the accounts mentioned in the tweet.\n",
    "\n",
    "While the hashtag network gave us an overview over the topics during the election campaign, the mentions network can show us which accounts were referred to the most in the analyzed tweets. This gives us the possibility to detect key figures of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50348211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot, G = plot_network(**mention_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575adca",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "We can observe, that the detected clusters have a large overlap with the different political parties. The parties <i>FDP</i>, <i>Die Grünen</i>, <i>AfD</i> and <i>Die Linke</i> each have their own cluster, while <i>SPD</i> and <i>CDU</i> are sharing a cluster. The network also allows us to identify for each political party their most prominent party member: Christian Lindner (<i>FDP</i>), Cem Özdemir (<i>Die Grünen</i>), Beatrice von Storch (<i>AfD</i>) and Martin Schulz (<i>SPD</i>). For <i>Die Linke</i> Sarah Wagenknecht and Dietmar Bartsch are equal prominent. The results did not show a prominent figure for the <i>CDU</i>. In the <i>SPD</i>and<i>CDU</i> Cluster we can see a subgroup of media companies like Spiegel, Bild, ARD, etc. which are closely connected with eachother. This allows the assumption that some tweets were refering to articles written by those companies. Given, that as mentioned previously, <i>SPD</i> and <i>CDU/CS</i> formed the government before the 2017 election this result is not surprising.\n",
    "The last cluster can be found around Peter Tauber, he was involved in a long twitter discussion in which he has drawn anger upon himself because of his statement \"Wenn Sie was Ordentliches gelernt haben, brauchen Sie keine drei Minijobs\" (If you have learned something proper, you do not need three mini-jobs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f375f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the network graph\n",
    "now = datetime.now()\n",
    "datetime_string = now.strftime(\"%d-%m-%Y_%Hh%M\")\n",
    "\n",
    "# Save graph as html\n",
    "#save(plot, filename=f\"{title}_{datetime_string}.html\")\n",
    "\n",
    "# Save graph in gephi format\n",
    "#networkx.write_gexf(G,f\"{title}_{datetime_string}.gexf\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
